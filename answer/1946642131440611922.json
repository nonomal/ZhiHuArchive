{
  "answer_type": "normal",
  "author": {
    "avatar_url": "https://pic1.zhimg.com/v2-531a5c925d857e1a3b944414bbd451c6_l.jpg?source=2c26e567",
    "avatar_url_template": "https://picx.zhimg.com/v2-531a5c925d857e1a3b944414bbd451c6.jpg?source=2c26e567",
    "badge": [],
    "badge_v2": {
      "detail_badges": [],
      "icon": "",
      "merged_badges": [],
      "night_icon": "",
      "title": "钻研人类记忆，探索复习算法。改善教育公平，践行自由学习。"
    },
    "gender": 1,
    "headline": "钻研人类记忆，探索复习算法。改善教育公平，践行自由学习。",
    "id": "3c9990a12cdbcd92e20b1387b160f0a3",
    "is_advertiser": false,
    "is_org": false,
    "is_privacy": false,
    "name": "Jarrett Ye",
    "type": "people",
    "url": "https://api.zhihu.com/people/3c9990a12cdbcd92e20b1387b160f0a3",
    "url_token": "JarrettYe",
    "user_type": "people"
  },
  "biz_ext": {
    "share_guide": {
      "has_positive_bubble": false,
      "has_time_bubble": false,
      "hit_share_guide_cluster": false
    }
  },
  "comment_count": 2,
  "content": "<p data-pid=\"7cqID312\">不太行，因为我们需要 ground truth。市场就是 ground truth。没有 ground truth，AI 可能会陷入错误的优化而无法被纠正。</p><p data-pid=\"2er0OaDY\">让赛博 Gwern Branwen 来回答一下：</p><h2>市场作为优化的基准真相</h2><p data-pid=\"eATPUVyy\">经济系统（以及许多其他复杂系统）是一个<b>双层嵌套的优化问题</b>。AI 计划经济的设想只看到了其中一层，却忽略了至关重要、无法被替代的另一层。</p><p data-pid=\"H_qXpePF\">这两层分别是：</p><ol><li data-pid=\"cljY62oS\"><b>内部优化层（AI 计划）</b>：这一层快速、高效，能解决极其复杂的规划问题（如谷歌的数据中心、沃尔玛的物流）。它优化的是<b>代理指标</b>或内部设定的损失函数（比如用户点击率、生产效率）。<br/><br/></li><li data-pid=\"EkAie0M4\"><b>外部约束层（市场/演化）</b>：这一层缓慢、粗暴、效率低下，但它基于无法作弊的<b>「基准真相」（Ground Truth）</b>，比如利润和破产。</li></ol><p data-pid=\"Dp6BdlpW\">AI 计划经济的问题在于，它是一个强大的「内部优化器」，但它优化的目标是人为设定的，可能存在偏差，最终会与现实脱节。而市场（或演化）作为「外部约束」，通过<b>破产</b>这个终极的、无情的反馈机制，来检验和约束内部计划，确保其方向不会偏离创造真实价值的轨道。</p><p data-pid=\"faF5CkzJ\">简而言之，AI 可以胜任「计划」，但这个「计划」必须被一个基于「基准真相」的市场所检验和约束。用 AI 完全取代市场，就等于拆掉了保证系统不偏离现实的最终保险。</p><h3>文章相关片段引用</h3><p data-pid=\"E6FQrY1V\"><b>关于计划经济的内在难题</b></p><blockquote data-pid=\"539yiCjb\">但规划之所以只在这些领域内可行，是因为赚钱这个目标，为公司（或类似公司的实体）提供了一个既明确又狭隘的目标函数。而为整个经济进行规划，即便在最乐观的假设下，在可预见的未来也是一项棘手的任务，<b>至于如何决定一份计划，我们更是对其间的难题束手无策。</b>在《红色丰裕》中角色们所梦想的那种高效计划经济，我们根本不知道如何实现，即便我们愿意为此接受独裁统治。</blockquote><p data-pid=\"vqkf5ZcD\"><b>关于双层优化模式的实例（AI 玩游戏）</b></p><blockquote data-pid=\"0ORwiSHy\">最终目标是获胜，基准真相的奖励是胜负结果，但仅仅从胜负中学习，效率极低……相比之下，游戏内的得分是一种信息密度高得多的监督信号……但问题是，它与最终的胜负只有间接关系；一个智能体可能会只顾自己刷分，却忽略了与敌人交战或与队友协调，最终导致团队失败……<b>因此，这个双层问题正是利用了缓慢的「外部」信号或损失函数（获胜），来塑造那个负责大部分学习任务的、更快速的「内部」损失函数（游戏内得分）。</b></blockquote><p data-pid=\"2eiYJX81\"><b>关于市场作为最终的「基准真相」检验者</b></p><blockquote data-pid=\"pvI2OXF2\">尽管各种内部的组织与规划算法功能强大，远胜于演化或市场竞争，但它们优化的终究是代理的内部损失函数，而非最终目标。<b>因此，它们必须受到一个基于基准真相的外部损失函数的约束。</b>对这种外部损失的依赖可以也应当被减少，但只要内部损失函数所收敛的最优点，与基准真相的最优点存在差异，那么将其完全移除便是不可取的。</blockquote><hr/><h2>难道不能用其他东西来代替市场作为最终的基准真相吗？</h2><p data-pid=\"JykJfCeD\"><b>极其困难，因为几乎所有你能想到的替代品，其本身都属于「内部损失函数」（代理指标），而不是「基准真相」。</b></p><p data-pid=\"rtk9Z5mS\">市场作为「基准真相」的独特之处，不在于它有多「好」或多「道德」，而在于它的机制<b>强制性地与现实世界进行残酷而直接的交互</b>。它的核心是<b>自愿的、有成本的交换</b>，最终的反馈（利润/破产）是一个无法长期伪造的、整合了无数个体偏好和现实约束的信号。</p><p data-pid=\"WgTNwDLk\">让我们用双层优化逻辑来审视一些可能的替代方案：</p><h3>1. 替代方案：民主投票 / 公众意愿</h3><p data-pid=\"_aORQK0q\">让全民投票决定生产什么、如何分配。</p><ul><li data-pid=\"IZL2DDmZ\"><b>为什么这不是基准真相？</b> 这衡量的是<b>「表达出来的偏好」（Stated Preference）</b>，而不是<b>「付出代价的偏好」（Revealed Preference）</b>。人们可以轻易地投票支持「给每个人发一辆车」，但这个投票本身并没有揭示他们是否愿意为此承担相应的成本（更高的税收、资源枯竭等）。它很容易被民粹主义、短期思维和信息宣传所操控，变成一个可以被「游戏化」的代理指标，而不是经济现实的真实反映。</li></ul><h3>2. 替代方案：专家委员会 / 科学规划</h3><p data-pid=\"KMgACn1c\">由最顶尖的科学家、经济学家和社会学家组成一个委员会，来设计最优的经济计划。</p><ul><li data-pid=\"jzWM7QC0\"><b>为什么这不是基准真相？</b> 因为这个委员会本身就是一个<b>「内部优化器」</b>。他们依赖的是模型、数据和预测，而这些都可能出错。谁来挑选专家？专家们优化的目标（他们自己的「内部损失函数」）是什么？这个系统缺乏一个外部的、残酷的反馈机制来告诉他们「你们的整个模型都错了」。它最终会陷入傲慢的「规划者谬误」，与真实世界的需求脱节。</li></ul><h3>3. 替代方案：人类福祉指标（如幸福指数、健康水平、寿命）</h3><p data-pid=\"wnhlEODV\">用 AI 来优化一个旨在最大化国民幸福总值（GNH）、人均寿命或健康水平的经济体。</p><ul><li data-pid=\"mXAZ8-hQ\"><b>为什么这不是基准真相？</b> 这是最诱人但也最危险的替代方案，因为它完美地体现了<b>古德哈特法则</b>（「当一个指标成为目标时，它就不再是一个好指标」）。如果你让整个经济体去优化一个可测量的「幸福分数」，那么所有机构都会开始「刷分」，而不是真正提升人们的福祉。人们会学会如何在问卷上报告自己更幸福，系统会奖励那些能产出漂亮数据的项目。很快，这个指标就会和真实的人类繁荣状态脱钩，变成一个被彻底「游戏化」的代理指标。</li></ul><h3>4. 替代方案：物理/生态约束（如碳排放、资源消耗）</h3><p data-pid=\"MPNeCWKR\">让AI在地球物理和生态系统的硬性约束下，规划一个可持续的经济。</p><ul><li data-pid=\"4MxkVssf\"><b>为什么这不是基准真相？</b> 这是一个非常重要的<b>约束条件</b>，但它不是一个完整的<b>目标函数</b>。物理定律确实是「基准真相」，你无法与之争辩。但这只能告诉我们<b>不能做什么</b>（比如不能无限制排放二氧化碳），却不能告诉我们在所有可持续的可能性中，我们<b>应该做什么</b>。它解决了生存问题，但没有解决在一个可持续的框架内，如何最好地满足数十亿人复杂、多变且主观的需求的问题。</li></ul><hr/><h3>结论：为什么市场（目前）无法被替代</h3><p data-pid=\"LEhGYsZz\">市场的残酷之处恰恰是它的价值所在：<b>破产是最终的、不可辩驳的反馈</b>。一个公司倒闭，不是因为它在某个内部指标上得分低，而是因为它无法再说服足够多的人，用他们自己辛苦赚来的、有限的资源来交换它的产品或服务。这个信号是<b>去中心化的、涌现的、且直接与个体付出代价的真实选择相关联</b>。</p><p data-pid=\"VfSDtHqP\">因此，问题不在于用AI计划来<b>取代</b>市场，而在于理解它们之间的<b>主从关系</b>。AI 和强大的规划能力是「聪明的内部优化器」，应该被用来在公司、组织内部尽可能地提高效率。而市场，则是那个缓慢、粗暴但基于「基准真相」的「外部约束者」，它通过利润和破产的最终裁决，来确保所有这些聪明的内部计划最终没有偏离为人类创造真实价值的轨道。</p><h3>文章相关片段引用</h3><p data-pid=\"YnK8MqdB\"><b>关于计划经济无法决定最终目标</b></p><blockquote data-pid=\"tMD4RnLz\">但规划之所以只在这些领域内可行，是因为赚钱这个目标，为公司（或类似公司的实体）提供了一个既明确又狭隘的目标函数。<b>而为整个经济进行规划，即便在最乐观的假设下，在可预见的未来也是一项棘手的任务，至于如何决定一份计划，我们更是对其间的难题束手无策。</b></blockquote><p data-pid=\"VFWHOkok\"><b>关于内部指标与最终目标的脱节（以 AI 玩游戏为例）</b></p><blockquote data-pid=\"imwGz1ZV\">最终目标是获胜，基准真相的奖励是胜负结果……但问题是，它（游戏内得分）与最终的胜负只有间接关系；一个智能体可能会只顾自己刷分，却忽略了与敌人交战或与队友协调，最终导致团队失败……因此，这个双层问题正是利用了缓慢的「外部」信号或损失函数（获胜），来塑造那个负责大部分学习任务的、更快速的「内部」损失函数。</blockquote><p data-pid=\"h6LJhuBH\"><b>关于破产作为最终的、无法伪造的现实检验</b></p><blockquote data-pid=\"VohpiiLl\">破产，伟哉：它是一道万丈深渊，一切虚伪，无论公私，终将沉沦其中，烟消云散；从其诞生之初，这便是它们注定的归宿。因为自然是真实的，而非谎言。你所说的、所行的任何谎言……都如同一张向「自然实在」开出的期票，终将被呈上要求兑付——而得到的回答是：查无此款。</blockquote><hr/><h2>相关文章</h2><a href=\"https://zhuanlan.zhihu.com/p/1944108824375060346\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\"internal\">演化：强化学习的最终保障</a><p></p>",
  "content_need_truncated": false,
  "created_time": 1756895651,
  "excerpt": "不太行，因为我们需要 ground truth。市场就是 ground truth。没有 ground truth，AI 可能会陷入错误的优化而无法被纠正。 让赛博 Gwern Branwen 来回答一下： 市场作为优化的基准真相经济系统（以及许多其他复杂系统）是一个 双层嵌套的优化问题。AI 计划经济的设想只看到了其中一层，却忽略了至关重要、无法被替代的另一层。这两层分别是： 内部优化层（AI 计划）：这一层快速、高效，能解决极其复杂的规划问题（如谷歌的数据…",
  "force_login_when_click_read_more": false,
  "id": "1946642131440611922",
  "is_jump_native": false,
  "link_card_info": {
    "https://zhuanlan.zhihu.com/p/1944108824375060346": "{\"card_type\":\"card_1\",\"display\":{\"title\":\"演化：强化学习的最终保障\",\"card_open_url\":\"https://zhuanlan.zhihu.com/p/1944108824375060346\",\"desc\":\"6 赞同 · 0 评论 \\u003ca class=\\\"tag type_a\\\"\\u003e文章\\u003c/a\\u003e\",\"content\":\"\\u003ca class=\\\"text normal/bold\\\" data-color=\\\"#444444\\\" data-night-color=\\\"#D3D3D3\\\"\\u003eJarrett Ye:\\u003c/a\\u003e 市场/演化可作为强化学习/优化的最终保障/基准真相：本文探讨科斯的企业理论、线性优化、深度强化学习、演化、多细胞生命、痛苦、互联网社区作为多层次优化问题之间的一些联系。 摘要为自由市场辩护的观点之一，是指出非市场机制无法解决计划与优化问题。然而，这一观点与科斯的企业悖论难以自洽。并且我注意到，随着计算机、算法和数据的进步，规模日益庞大的计划问题 的确正在被解决，这让前述观点更显窘迫。在 Cosma Shalizi …\",\"image\":{\"image_url\":\"https://picx.zhimg.com/v2-81c3fd4239aa0043afcd0d3fc6230788_r.jpg?source=172ae18b\",\"ratio\":1,\"is_video\":false},\"bg_type\":\"dark\"},\"source\":{\"content_type\":\"ARTICLE\",\"content_id\":\"1944108824375060346\"},\"za_data\":{\"attach_info\":\"\"}}"
  },
  "question": {
    "created": 1541260916,
    "detail": "",
    "id": "301176807",
    "question_type": "normal",
    "relationship": {},
    "title": "靠 AI 来实行计划经济可行吗？",
    "type": "question",
    "updated_time": 1542793220,
    "url": "https://api.zhihu.com/questions/301176807"
  },
  "relationship": {
    "upvoted_followees": []
  },
  "type": "answer",
  "voteup_count": 1
}